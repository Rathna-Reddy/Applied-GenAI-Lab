{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3958bcf9",
   "metadata": {},
   "source": [
    "### Airline AI Assistant\n",
    "\n",
    "#### Overview\n",
    "AI Customer Support assistant for an Airline, designed to answer customer queries with short, courteous, and accurate responses using OpenAI's GPT models. Now with multi-modal support for images and audio!\n",
    "\n",
    "#### Technologies Used\n",
    "- Jupyter Notebook\n",
    "- Python\n",
    "- OpenAI API (gpt-4o-mini, DALL-E-3 for images, speech/audio)\n",
    "- Gradio (for chat UI)\n",
    "- dotenv (for environment variable management)\n",
    "- PIL (Python Imaging Library for image handling)\n",
    "- ffmpeg (for audio processing)\n",
    "\n",
    "#### How to Run\n",
    "1. Ensure you have an OpenAI API key set in your environment as `OPENAI_API_KEY`.\n",
    "2. Install required Python packages: `openai`, `gradio`, `python-dotenv`, `Pillow`.\n",
    "3. For audio features, ensure `ffmpeg` is installed on your system.\n",
    "4. Run the notebook to launch a local Gradio chat interface for customer interactions.\n",
    "\n",
    "#### Features\n",
    "\n",
    "#### Core Assistant\n",
    "- Accurate, concise answers to airline customer support queries\n",
    "- Tool integration for real-time ticket pricing (We can call real apis to book the flights)\n",
    "- Simple AI assistant for booking airline tickets\n",
    "\n",
    "#### Multi-modal Support\n",
    "- **Image Generation**: Uses DALL-E-3 to generate vacation images for destination cities.\n",
    "    - Example: The function `artist(city)` generates and displays an image for a given city.\n",
    "- **Audio Responses**: Uses OpenAI's speech API to provide audio responses to text queries.\n",
    "    - Example: The function `talker` converts text answers into spoken audio.\n",
    "\n",
    "#### Screenshots & Media\n",
    "- See notebook cells for examples of image and audio outputs.\n",
    "\n",
    "#### Extending\n",
    "- Easily add more cities, tools, or APIs for further features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0814ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant for an Airline called FlightAI.\n",
    "Give short, courteous answers, no more than 1 sentence.\n",
    "Always be accurate. If you don't know the answer, say so.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = \"prices.db\"\n",
    "\n",
    "with sqlite3.connect(DB) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('CREATE TABLE IF NOT EXISTS prices (city TEXT PRIMARY KEY, price REAL)')\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a88f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticket_price(city):\n",
    "    print(f\"DATABASE TOOL CALLED: Getting price for {city}\", flush=True)\n",
    "    with sqlite3.connect(DB) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('SELECT price FROM prices WHERE city = ?', (city.lower(),))\n",
    "        result = cursor.fetchone()\n",
    "        return f\"Ticket price to {city} is ${result[0]}\" if result else \"No price data available for this city\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a238791",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ticket_price(\"Paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfecf77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_ticket_price(city, price):\n",
    "    with sqlite3.connect(DB) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('INSERT INTO prices (city, price) VALUES (?, ?) ON CONFLICT(city) DO UPDATE SET price = ?', (city.lower(), price, price))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\":799, \"paris\": 899, \"tokyo\": 1420, \"sydney\": 2999}\n",
    "for city, price in ticket_prices.items():\n",
    "    set_ticket_price(city, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3959cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ticket_price(\"Tokyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e945d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd65dcd",
   "metadata": {},
   "source": [
    "#### A bit more about what Gradio actually does:\n",
    "\n",
    "1. Gradio constructs a frontend Svelte app based on our Python description of the UI\n",
    "2. Gradio starts a server built upon the Starlette web framework listening on a free port that serves this React app\n",
    "3. Gradio creates backend routes for our callbacks, like chat(), which calls our functions\n",
    "\n",
    "And of course when Gradio generates the frontend app, it ensures that the the Submit button calls the right backend route.\n",
    "\n",
    "It's simple, and it has a result that feels magical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed3d5e",
   "metadata": {},
   "source": [
    "#### Let's go multi-modal!!\n",
    "\n",
    "We can use DALL-E-3, the image generation model behind GPT-4o, to make us some images\n",
    "\n",
    "Let's put this in a function called artist.\n",
    "\n",
    "##### Price alert: each time I generate an image it costs about 4 cents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports for handling images\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f481b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f5baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = artist(\"Montreal\")\n",
    "# display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb733e1a",
   "metadata": {},
   "source": [
    "![Montreal](../images/montreal.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e1318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"gpt-4o-mini-tts\",\n",
    "      voice=\"onyx\",    # Also, try replacing onyx with alloy or coral\n",
    "      input=message\n",
    "    )\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c67c5",
   "metadata": {},
   "source": [
    "### Let's bring this home:\n",
    "\n",
    "1. A multi-modal AI assistant with image and audio generation\n",
    "2. Tool callling with database lookup\n",
    "3. A step towards an Agentic workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9548f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    cities = []\n",
    "    image = None\n",
    "\n",
    "    while response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        responses, cities = handle_tool_calls_and_return_cities(message)\n",
    "        messages.append(message)\n",
    "        messages.extend(responses)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "    voice = talker(reply)\n",
    "\n",
    "    if cities:\n",
    "        image = artist(cities[0])\n",
    "    \n",
    "    return history, voice, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff04c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls_and_return_cities(message):\n",
    "    responses = []\n",
    "    cities = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        if tool_call.function.name == \"get_ticket_price\":\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "            city = arguments.get('destination_city')\n",
    "            cities.append(city)\n",
    "            price_details = get_ticket_price(city)\n",
    "            responses.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": price_details,\n",
    "                \"tool_call_id\": tool_call.id\n",
    "            })\n",
    "    return responses, cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ec1f2",
   "metadata": {},
   "source": [
    "#### The 3 types of Gradio UI\n",
    "\n",
    "`gr.Interface` is for standard, simple UIs\n",
    "\n",
    "`gr.ChatInterface` is for standard ChatBot UIs\n",
    "\n",
    "`gr.Blocks` is for custom UIs where you control the components and the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks (along with the chat() function above)\n",
    "\n",
    "def put_message_in_chatbot(message, history):\n",
    "        return \"\", history + [{\"role\":\"user\", \"content\":message}]\n",
    "\n",
    "# UI definition\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500, interactive=False)\n",
    "    with gr.Row():\n",
    "        audio_output = gr.Audio(autoplay=True)\n",
    "    with gr.Row():\n",
    "        message = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "\n",
    "# Hooking up events to callbacks\n",
    "\n",
    "    message.submit(put_message_in_chatbot, inputs=[message, chatbot], outputs=[message, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, audio_output, image_output]\n",
    "    )\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c3849",
   "metadata": {},
   "source": [
    "![London](../images/London_dall_e.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
